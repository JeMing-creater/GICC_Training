import os
from sympy import im
import yaml
import pandas as pd
import numpy as np
import torch
from easydict import EasyDict
from monai.data import DataLoader, Dataset as MonaiDataset
from monai.transforms import (
    MapTransform,
    Compose,
    LoadImaged,
    EnsureChannelFirstd,
    Orientationd,
    Resized,
    ScaleIntensityRangePercentilesd,
    ConcatItemsd,
    DeleteItemsd,
    EnsureTyped,
    RandRotated,
    RandFlipd,
    RandShiftIntensityd,
    RandScaleIntensityd
)

# ==========================================
# 1. æ ¸å¿ƒå°è£…ï¼šNonEmptyDataLoader
# ==========================================

class NonEmptyDataLoader:
    """
    ã€Loader åŒ…è£…å™¨ã€‘
    è‡ªåŠ¨è¿‡æ»¤æ‰ DataLoader äº§ç”Ÿçš„ None (ç©ºBatch)ï¼Œ
    ç¡®ä¿å¤–éƒ¨å¾ªç¯æ°¸è¿œåªæ¥æ”¶åˆ°æœ‰æ•ˆæ•°æ®ã€‚
    """
    def __init__(self, dataloader):
        self.loader = dataloader

    def __iter__(self):
        iterator = iter(self.loader)
        while True:
            try:
                batch = next(iterator)
                if batch is not None:
                    yield batch
                else:
                    # é‡åˆ° Noneï¼Œé™é»˜è·³è¿‡ï¼Œè‡ªåŠ¨è·å–ä¸‹ä¸€ä¸ª
                    # print("âš ï¸ [Loader] è‡ªåŠ¨è·³è¿‡ä¸€ä¸ªç©º Batch...")
                    continue
            except StopIteration:
                break

    def __len__(self):
        # æ³¨æ„ï¼šå®é™…äº§å‡ºçš„ batch æ•°é‡å¯èƒ½å°‘äº len(loader)ï¼Œå› ä¸ºéƒ¨åˆ†è¢«è·³è¿‡äº†
        return len(self.loader)

# ==========================================
# 2. è‡ªå®šä¹‰ Transforms & Dataset
# ==========================================

class CheckAndFixDimensionsd(MapTransform):
    """
    ã€ä¿®å¤ 4D é”™è¯¯ã€‘
    æ£€æŸ¥å›¾åƒå’Œæ ‡ç­¾ç»´åº¦ã€‚
    """
    def __init__(self, keys, allow_missing_keys=False):
        super().__init__(keys, allow_missing_keys)

    def __call__(self, data):
        d = dict(data)
        for key in self.key_iterator(d):
            if key not in d: continue
            img = d[key]
            # å½¢çŠ¶å¯èƒ½æ˜¯ (H,W,D) æˆ– (H,W,D,C)
            if len(img.shape) == 4:
                # æƒ…å†µ 1: ä¼ª4D (H, W, D, 1) -> é™ç»´
                if img.shape[-1] == 1:
                    if hasattr(img, "squeeze"): 
                        d[key] = img.squeeze(-1)
                    else:
                        d[key] = np.squeeze(img, axis=-1)
                # æƒ…å†µ 2: å¤šé€šé“4D -> å¼ºåˆ¶å–ç¬¬0é€šé“
                else:
                    print(f"  âš ï¸ [Fix4D] å¤šé€šé“æ•°æ® {key} {img.shape}ï¼Œå¼ºåˆ¶å–ç¬¬0å¸§")
                    d[key] = img[..., 0]
        return d

class SafeDataset(MonaiDataset):
    """
    ã€å®‰å…¨ Datasetã€‘
    æ•è·æ‰€æœ‰ Transform ä¸­çš„é”™è¯¯ï¼Œè¿”å› Noneã€‚
    """
    def __getitem__(self, index):
        try:
            return super().__getitem__(index)
        except Exception as e:
            sample_info = self.data[index]
            sample_id = sample_info.get('id', 'Unknown')
            # æ‰“å°ç®€çŸ­çš„é”™è¯¯æ—¥å¿—
            print(f"\nâŒ [Read Error] è·³è¿‡æ ·æœ¬ ID: {sample_id}")
            print(f"   åŸå› : {str(e)}")
            return None

def collate_fn_ignore_none(batch):
    """
    ã€å®‰å…¨ Collateã€‘è¿‡æ»¤ None
    """
    batch = [x for x in batch if x is not None]
    if len(batch) == 0:
        return None
    from monai.data import list_data_collate
    return list_data_collate(batch)

# ==========================================
# 3. è·¯å¾„æŸ¥æ‰¾ä¸ ID åŒ¹é…é€»è¾‘
# ==========================================
FOLDER_ALIASES = {
    "T2_FS": ["T2_FS", "T2", "t2", "T2FS"],
    "ADC":   ["ADC", "adc", "Adc"],
    "V":     ["V", "v", "Venous", "venous"]
}

def find_modality_path(patient_folder, modality_name):
    candidates = FOLDER_ALIASES.get(modality_name, [modality_name])
    for alias in candidates:
        target_path = os.path.join(patient_folder, alias)
        if os.path.exists(target_path):
            return target_path, alias
    return None, None

def build_folder_index(data_folder):
    if not os.path.exists(data_folder): return {}
    index = {}
    try:
        subfolders = [f for f in os.listdir(data_folder) if os.path.isdir(os.path.join(data_folder, f))]
    except Exception: return {}
    
    for real_name in subfolders:
        clean_key = real_name.lstrip('0')
        if clean_key == "": clean_key = "0"
        index[clean_key] = real_name
    print(f"âœ… å·²ç´¢å¼• {len(index)} ä¸ªç—…äººæ–‡ä»¶å¤¹")
    return index

def validate_patient_data(data_folder, real_folder_name, required_modalities, excel_id):
    p_path = os.path.join(data_folder, real_folder_name)
    data_entry = {"id": real_folder_name, "excel_id": excel_id}
    
    for mod in required_modalities:
        mod_folder, _ = find_modality_path(p_path, mod)
        if mod_folder is None: return False, {}, f"ç¼ºå¤±æ¨¡æ€æ–‡ä»¶å¤¹: {mod}"
        
        img_file = os.path.join(mod_folder, f"{real_folder_name}.nii.gz")
        if not os.path.exists(img_file): return False, {}, f"ç¼ºå¤±å›¾åƒ: {mod}"
        
        seg_file = os.path.join(mod_folder, f"{real_folder_name}seg.nii.gz")
        if not os.path.exists(seg_file): 
            return False, {}, f"ç¼ºå¤± Label: {mod}"
        
        data_entry[f"image_{mod}"] = img_file
        data_entry[f"label_{mod}"] = seg_file

    return True, data_entry, None

def build_data_list(config_item, root_dir, leapfrog_list, data_folder_name="All", required_modalities=[], tag=""):
    excel_path = os.path.join(root_dir, config_item.filename)
    data_folder = os.path.join(root_dir, data_folder_name)
    col_idx = config_item.id_col_index 
    
    if not os.path.exists(excel_path):
        return [], [{"id": "File Missing", "reason": f"Excelä¸å­˜åœ¨"}]
    try:
        df = pd.read_excel(excel_path)
    except Exception as e:
        return [], [{"id": "Read Error", "reason": str(e)}]
    
    folder_index = build_folder_index(data_folder)
    raw_ids_series = df.iloc[:, col_idx].astype(str).str.strip()
    ids = [x for x in raw_ids_series.unique() if x.lower() != 'nan' and x != '']

    valid_list, failed_list = [], []
    leapfrog_set = set(str(x).strip() for x in leapfrog_list)
    skipped_count = 0
    
    print(f"[{tag}] æ‰«æ {len(ids)} ä¸ªID...")

    for raw_id in ids:
        if raw_id in leapfrog_set:
            skipped_count += 1; continue

        clean_key = raw_id.lstrip('0')
        if clean_key == "": clean_key = "0"
        
        real_folder_name = folder_index.get(clean_key)
        
        if real_folder_name:
            if real_folder_name in leapfrog_set:
                skipped_count += 1; continue
            
            is_valid, entry, msg = validate_patient_data(data_folder, real_folder_name, required_modalities, raw_id)
            if is_valid:
                valid_list.append(entry)
            else:
                failed_list.append({"id": f"{raw_id}->{real_folder_name}", "reason": msg})
        else:
            failed_list.append({"id": raw_id, "reason": "æœªæ‰¾åˆ°åŒ¹é…æ–‡ä»¶å¤¹"})
            
    if skipped_count > 0: print(f"[{tag}] è·³è¿‡ {skipped_count} ä¸ªé»‘åå•æ ·æœ¬")
    return valid_list, failed_list

# ==========================================
# 4. æ•°æ®å¤„ç†æµæ°´çº¿ (Transforms)
# ==========================================

def get_transforms(cfg, stage="train"):
    req_mods = cfg.use_modalities
    image_keys = [f"image_{m}" for m in req_mods] 
    label_keys = [f"label_{m}" for m in req_mods]
    all_load_keys = image_keys + label_keys
    
    transforms = []

    # 1. åŠ è½½ & ç»´åº¦ä¿®å¤ (å¿…é¡»åœ¨æœ€å‰é¢)
    transforms.extend([
        LoadImaged(keys=all_load_keys),
        CheckAndFixDimensionsd(keys=all_load_keys), # ä¿®å¤4Dæ•°æ®
        EnsureChannelFirstd(keys=all_load_keys),
        Orientationd(keys=all_load_keys, axcodes="RAS"),
    ])

    # 2. ç»Ÿä¸€å°ºå¯¸
    interp_modes = ['trilinear'] * len(image_keys) + ['nearest'] * len(label_keys)
    transforms.append(
        Resized(
            keys=all_load_keys, 
            spatial_size=cfg.target_size, 
            mode=interp_modes 
        )
    )

    # 3. æ‹¼æ¥æ¨¡æ€
    transforms.extend([
        ConcatItemsd(keys=image_keys, name="image", dim=0),
        ConcatItemsd(keys=label_keys, name="seg_label", dim=0),
        DeleteItemsd(keys=all_load_keys) 
    ])

    # 4. å¼ºåº¦å½’ä¸€åŒ–
    transforms.append(
        ScaleIntensityRangePercentilesd(
            keys=["image"], lower=0.5, upper=99.5, b_min=0.0, b_max=1.0, clip=True
        )
    )

    # 5. æ•°æ®å¢å¼º (ä»…è®­ç»ƒé›†)
    if stage == "train":
        transforms.extend([
            RandRotated(
                keys=["image", "seg_label"],
                range_x=0.5, range_y=0.5, range_z=0.5,
                prob=0.5,
                mode=["bilinear", "nearest"],
                padding_mode="border",
            ),
            RandFlipd(
                keys=["image", "seg_label"],
                prob=0.5, spatial_axis=[0, 1, 2]
            ),
            RandShiftIntensityd(keys=["image"], offsets=0.1, prob=0.5),
            RandScaleIntensityd(keys=["image"], factors=0.1, prob=0.5)
        ])

    transforms.append(EnsureTyped(keys=["image", "seg_label"]))
    return Compose(transforms)

# ==========================================
# 5. Loader æ„å»ºä¸»å‡½æ•°
# ==========================================

def print_report(name, valid_list, failed_list):
    print(f"\n{'='*20} {name} æ•°æ®æŠ¥å‘Š {'='*20}")
    print(f"âœ… æˆåŠŸåŠ è½½: {len(valid_list)} ä¾‹")
    print(f"âŒ è¯»å–å¤±è´¥: {len(failed_list)} ä¾‹")
    if len(failed_list) > 0:
        print("-" * 60)
        for fail in failed_list: 
            print(f"{str(fail['id']):<25} | {fail['reason']}")
        print("-" * 60)
    print("\n")

def get_loaders(cfg):
    root_dir = cfg.root_dir
    req_mods = cfg.use_modalities
    leapfrog_list = cfg.get("leapfrog", [])
    
    print(f"ğŸš€ åˆå§‹åŒ– Loader | ç›®æ ‡å°ºå¯¸: {cfg.target_size}")

    mei_valid, mei_fail = build_data_list(cfg.excel_configs.mei, root_dir, leapfrog_list, "All", req_mods, "Mei")
    gz_valid, gz_fail = build_data_list(cfg.excel_configs.gz, root_dir, leapfrog_list, "All", req_mods, "GZ")
    train_list = mei_valid + gz_valid
    train_fail = mei_fail + gz_fail
    print_report("Train Set", train_list, train_fail)

    dg_valid, dg_fail = build_data_list(cfg.excel_configs.dg, root_dir, leapfrog_list, "All", req_mods, "DG")
    print_report("Val Set", dg_valid, dg_fail)
    
    if len(train_list) == 0: raise ValueError("è®­ç»ƒé›†ä¸ºç©º")

    train_ds = SafeDataset(data=train_list, transform=get_transforms(cfg, "train"))
    
    val_ds = SafeDataset(data=dg_valid, transform=get_transforms(cfg, "val")) 
    
    train_ds = SafeDataset(data=train_list, transform=get_transforms(cfg, "train"))
    val_ds = SafeDataset(data=dg_valid, transform=get_transforms(cfg, "val")) 

    # åˆ›å»ºåŸå§‹ Loader
    _train_loader = DataLoader(
        train_ds, batch_size=cfg.batch_size, shuffle=True, 
        num_workers=cfg.num_workers, collate_fn=collate_fn_ignore_none
    )
    _val_loader = DataLoader(
        val_ds, batch_size=1, shuffle=False, 
        num_workers=cfg.num_workers, collate_fn=collate_fn_ignore_none
    )

    # ã€æ ¸å¿ƒã€‘åŒ…è£¹ä¸€å±‚ NonEmptyDataLoader
    train_loader = NonEmptyDataLoader(_train_loader)
    val_loader = NonEmptyDataLoader(_val_loader)

    return train_loader, val_loader

# ==========================================
# 6. è°ƒè¯•/è¯Šæ–­å·¥å…·
# ==========================================
def check_batch_statistics(batch):
    # ç°åœ¨ batch æ°¸è¿œä¸å¯èƒ½æ˜¯ Noneï¼Œé™¤é Loader çœŸçš„æ²¡ä¸œè¥¿äº†
    images = batch["image"]
    labels = batch["seg_label"]
    ids = batch.get("id", ["Unknown"])
    
    img_np = images.detach().cpu().numpy()
    lbl_np = labels.detach().cpu().numpy()
    
    print(f"\n{'>'*5} Batch Diagnosis (ID: {ids[0]}...) {'>'*5}")
    print(f"Shape: Img {img_np.shape}, Lbl {lbl_np.shape}")
    
    if img_np.shape[1] != lbl_np.shape[1]:
        print(f"âŒ è­¦å‘Š: é€šé“æ•°ä¸åŒ¹é…! Image={img_np.shape[1]}, Label={lbl_np.shape[1]}")
    else:
        print(f"âœ… é€šé“æ•°å¯¹é½: {img_np.shape[1]} æ¨¡æ€")


if __name__ == "__main__":
    with open("config.yml", "r", encoding="utf-8") as f:
        cfg = EasyDict(yaml.load(f, Loader=yaml.FullLoader)).data
        
    train_loader, val_loader = get_loaders(cfg)
    
    for batch_data in train_loader:
        print(batch_data["image"].shape)
        print(batch_data["seg_label"].shape)
        
    for batch_data in val_loader:
        print(batch_data["image"].shape)
        print(batch_data["seg_label"].shape)